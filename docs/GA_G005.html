<!DOCTYPE html>
<html lang="en">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<head>
    <title>Block Art</title>
    <link rel="stylesheet" href="GA_Pages.css">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-120550704-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-120550704-1');
    </script>
    <!--jQuery api host from Google-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
    <style>
        #tag_img{
            width: 9em;
            height: 11em;
        }
    </style>
</head>

<body>
    <h2>G005 - Block Art</h2>
    <h5>Matthew Yu</h5>
    <h5>November 19th, 2018</h5>
    <hr>
    <img src="description/G005/self.png" id="tag_img">
    <p>
        This program converts an image with a gradient across multiple surfaces,
        such as the sky, and turns the area into a solid color. The end result
        is "blocks" of color that match together, like puzzle pieces.
    </p>
    <p>
        The inspiration for this program from the music videos of Jason Mraz's
        summer 2018 album, <a href="https://www.youtube.com/watch?v=BpVzXWdJBq0&index=5&list=PLAHwrrBPBeO44MBUiF4eHjvIkCztQfGri">
        <i>Know</i></a>.
    </p>
    <p>
        The program works by sectioning an image by the color gradient across each
        pixel. If the color gradient is larger than a threshold, then a new object
        is created. The algorithm used for this is also used for object detection
        for computer vision, called <a href="https://www.youtube.com/watch?v=hMIrQdX4BkE&t=11s">
        <i>connected components</i></a>.
    </p>
    <p>
        The specific algorithm written for this program is as follows:
        <br><br>
        <code>
            for a pixel in the image (we go iteratively, row by row):<br>
            &nbsp;&nbsp;check the top and left adjacent pixel<br>
            &nbsp;&nbsp;if variance (of neighbor color) > than a threshold:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;if the left neighbor only passes:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id pixel as same as the left pixel<br>
            &nbsp;&nbsp;&nbsp;&nbsp;if the top neighbor only passes:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id pixel as same as the top pixel<br>
            &nbsp;&nbsp;&nbsp;&nbsp;if both neighbors pass:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;add both ids to an equivalency list/correlation map<br>
            &nbsp;&nbsp;else start a new object id<br><br>
        </code>
        This part of the program, encapsulated into a <b>connected components</b> function,
        is followed by a postprocessing image coloring function. This <b>coloring</b> function
        updates the image (through P5.js's Pixel array) by taking the first
        pixel's color of an object and setting that as the color for every pixel
        part of that object. This essentially flattens the gradient across the image.
        <br><br>
        <code>
            for pixel in the image:<br>
            &nbsp;&nbsp;get the pixel id<br>
            &nbsp;&nbsp;search the correlation map for the associated base id and color<br><br>
        </code>
        This is a pretty short function, right?
        <br><br>
        The trick to this function is to have a helper function, <b>searchRef</b>
        that looks through the equivalency list data structure and finds the smallest
        object ID the input ID matches.
    </p>
    <img src="description/G005/Equivalency List.png">
    <p>
        This image is a pretty good representation of the objects identified
        in the connected component algorithm and searched in the searchRef function.
        A new object is created with an ID, and if there are no matching neighbors
        (left and top) then its equivalent ID is congruent.<br><br>
        But if there is two matching neighbors, the lower ID of the two becomes
        the equivalent ID and the higher one is the ID of the pixel.
    </p>
    <p>
        This is important because instead of merging the two similar objects
        at the time they are found (which isn't very efficient but easier to code)
        we want to be able to do a final pass after building the equivalency list.
        Making the higher ID be the ID of the pixel means all related pixels
        of the higher ID will be congruent to the lower ID when looking through
        searchRef.
        <br><br>
        For the table above, this means that 5 = 4 = 2, with 2 being the base ID.
        Three objects are being merged here! The final color for all pixels of
        the IDs 5, 4, and 2 will be white.
    </p>
    <p>
        Here are some of the results that I've made!
    </p>
    <!--G005 gallery-->
    <div class="flex-container">
        <section>
          <button class="accordion"><h2>G005</h2></button>
          <div id="G005" class="panel"></div>
          <script>
            let G005Container = document.getElementById("G005");
            let G005Pictures = ["png", "pixelSchool", "pixelSchool2", "pixelTurtle",
                "pixelTurtle2", "talonflame", "talonflame2", "concorde", "arjunFace"];
            for (let i = 1; i < G005Pictures.length; i++) {
                let src = "pictures/G005_Drawings/" + G005Pictures[i] + "." + G005Pictures[0];
                let img = new Image();
                img.src = src;
                G005Container.appendChild(img);
            }
          </script>
        </section>
    </div>
    <p>
        The parameter that adjusts how objects are sectioned and made is the
        variance. As the variance increases, less objects are formed since fewer
        pixels break through the variance threshold to become a new object. Vice
        versa, we see more detail in the image as the variance decreases.
        Similarly, the runtime of the algorithm and coloring functions are
        proportional to the variance. As more objects are created, the coloring
        function specifically has to look through more equivalent IDs before it
        can reach the base ID.
        <br><br>
        Here is an image showing the image change as variability increases
        [5, 10, 15, 20, 30].
    </p>
    <img src="description/G005/launch2_sum.png">
    <p>
        You can see the image gradually being eroded away as variance increases,
        so it's best to keep variance low, to like 10 on high detail images.
        I expected better results though if it's for something like the puzzle
        heart in the youtube video I linked at the start.
    </p>
    <p>
        One of the things I went back and fixed in version 3 of this program is
        a dedicated set() and get() method for the p5 Pixels array. The
        algorithms previously took up to an hour to do medium-large images, which
        was actually really terrible. The biggest reason for this is that P5JS's
        get and set methods for accessing the Pixel array are horribly bloated,
        which means directly accessing the array would increase your processing
        speed by at least a magnitude.
    </p>
    <p>
        So after writing my own direct access methods I benchmarked the difference
        between the two and was very pleasantly surprised. For the Talonflame image
        in my G005 gallery above, a 275x287 image, here were the results:
        <br>
        <ul>
            <li>Before: 345.591s/1.621s</li>
            <li>After: 1.388s/2.234s</li>
        </ul>
    </p>
    <p>
        The two differing values for each test being the correlated components
        and coloring function, respectively.
    </p>
    <p>
        I experienced a near 340x increase in speed! Now I'm able to run images
        like the SpaceX rocket launch photo above in a matter of minutes at 960x636
        pixels rather than a matter of hours.
    </p>
    <p>
        I'm currently considering more optimization fixes and algorithm changes
        to tweak the performance and results of this program.
        <ol>
            <li>Before running the color function, I want to run a function that
                runs through the equivalency list and updates all equivalent IDs
                to the base ID beforehand. This way every pixel doesn't have to
                recurse to the base ID when determining its color.</li>
            <li>Instead of running a connected components algorithm, I want to
                instead find objects using DBSCAN, which is an improved K means
                clustering algorithm. DBSCAN uses a density and a ball radius
                parameter, with which it uses to find all the related pixels
                within a nearby circle and thresholds it to the density in order
                to determine whether it is part of an object or not.</li>
        </ol>
    </p>
    <p>
        The DBSCAN suggestion is specifically based on my work on DBSCAN algorithm
        implementation for UT's IEEE RAS Region V committee, which is currently
        building an autonomous robot for a Mars Rover challenge. I was very
        surprised when I realized that connected components was a radius 1
        simplified implementation of DBSCAN, and am I currently thinking of
        implementing a equivalency list/correlation map to speed up the algorithm.
        You can find more about our project
        <a href="https://github.com/ut-ras/r5-2019/tree/vision/db_scan/DB_scan">here</a>!
        <br><br>
        If you have any suggestions, please feel free to contact me!
    </p>
    <!--expander for galleries-->
    <script>
      let acc = document.getElementsByClassName("accordion");
      for (let i = 0; i < acc.length; i++) {
        acc[i].addEventListener("click", function() {
          this.classList.toggle("active");
          let panel = this.nextElementSibling;
          let section = this.parentElement;
          if (panel.style.maxHeight) {
            panel.style.maxHeight = null;
            section.style.width = 48 + "%";
          } else {
            panel.style.maxHeight = panel.scrollHeight + 200 + "px";
            section.style.width = 98 + "%" ;
          }
        });
      }
    </script>
</body>
<footer>
    This page is part of a project to document and effectively communicate code
    and algorithms to people.
</footer>
